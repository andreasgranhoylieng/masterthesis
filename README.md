# Syringe Detection and Volume Estimation System

This repository contains a comprehensive system for syringe detection, tracking, and volume estimation using computer vision and deep learning. The system consists of three main components:

1. **Automatic Annotation with GroundingDINO** - For generating training data
2. **Keypoint Detection for Volume Estimation** - For measuring syringe plunger displacement
3. **Syringe Tracking** - For tracking multiple syringes in video streams

## Features

- ğŸ¯ Automatic annotation of syringe images using GroundingDINO
- ğŸ“ Precise volume estimation using keypoint detection
- ğŸ“¹ Real-time syringe tracking in video streams
- ğŸ“Š CSV export of volume measurements over time
- ğŸ¥ Webcam and video file support
- ğŸ“¦ Easy-to-use Jupyter Notebook interfaces

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/andreasgranhoylieng/masterthesis.git
   cd syringe-ml
   ```

2. Create and activate the conda environment:
   ```bash
   conda env create -f environment.yml
   conda activate syringe-ml
   ```

3. Install GroundingDINO weights:
   ```bash
   cd dino
   mkdir -p github_files
   wget https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth -O github_files/groundingdino_swint_ogc.pth
   cd ..
   ```

## Usage

### 1. Automatic Annotation with GroundingDINO
- Place your images or videos in `dino/images/` or `dino/videos/`
- Run `dino/main.ipynb` to generate annotations
- Annotations will be saved in Pascal VOC format
- These annotations can be uploaded to Roboflow

### 2. Volume Estimation with Keypoint Detection
1. Download datasets:
   ```bash
   jupyter notebook download_datasets.ipynb
   ```
2. Train the model:
   ```bash
   jupyter notebook volume_estimation/train.ipynb
   ```
3. Run inference:
   - For video files: `volume_estimation/pose_video_visualizer.ipynb`
   - For webcam: `volume_estimation/webcam_inference_pose.ipynb`

### 3. Syringe Tracking
1. Train the detection model:
   ```bash
   jupyter notebook syringe_tracking/train.ipynb
   ```
2. Run tracking:
   - For video files: `syringe_tracking/video_inference_od.ipynb`
   - For webcam: `syringe_tracking/webcam_inference_od.ipynb`

## Folder Structure

```
.
â”œâ”€â”€ dino/                     # GroundingDINO automatic annotation
â”‚   â”œâ”€â”€ images/               # Input images for annotation
â”‚   â”œâ”€â”€ videos/               # Input videos for annotation
â”‚   â”œâ”€â”€ annotations/          # Generated Pascal VOC annotations from images or videos
â”‚   â”œâ”€â”€ frames/               # Frames extracted from videos
â”‚   â”œâ”€â”€ github_files/         # GroundingDINO weights and configs
â”‚   â””â”€â”€ main.ipynb            # Annotation notebook
â”œâ”€â”€ volume_estimation/        # Volume estimation system
â”‚   â”œâ”€â”€ train.ipynb           # Training notebook
â”‚   â”œâ”€â”€ pose_video_visualizer.ipynb # Video processing
â”‚   â””â”€â”€ webcam_inference_pose.ipynb # Webcam inference
â”œâ”€â”€ syringe_tracking/         # Syringe tracking system
â”‚   â”œâ”€â”€ train.ipynb           # Training notebook
â”‚   â”œâ”€â”€ video_inference_od.ipynb # Video tracking
â”‚   â””â”€â”€ webcam_inference_od.ipynb # Webcam tracking
â”œâ”€â”€ datasets/                 # Dataset storage from Roboflow
â”œâ”€â”€ environment.yml           # Conda environment
â””â”€â”€ README.md                 # This file
```
