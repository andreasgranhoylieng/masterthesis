{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"input_video.mp4\"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot open video file: input_video.mp4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 160\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Create an instance and run video processing.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m calculator \u001b[38;5;241m=\u001b[39m SyringeVolumeCalculator()\n\u001b[0;32m--> 160\u001b[0m \u001b[43mcalculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_on_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 125\u001b[0m, in \u001b[0;36mSyringeVolumeCalculator.run_on_video\u001b[0;34m(self, input_video_path, output_video_path)\u001b[0m\n\u001b[1;32m    123\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(input_video_path)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot open video file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_WIDTH))\n\u001b[1;32m    127\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_HEIGHT))\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot open video file: input_video.mp4"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from typing import Tuple, Optional, Deque\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class SyringeVolumeCalculator:\n",
    "    def __init__(self) -> None:\n",
    "        self.model = YOLO(\"runs/pose/train-pose11x-v14/weights/best.pt\").eval()\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = \"mps\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "        self.volume_history: Deque[float] = deque(maxlen=3)\n",
    "        self.syringe_diameter: float = 1.0  # cm\n",
    "        self.ll_point: Optional[np.ndarray] = None\n",
    "        self.ul_point: Optional[np.ndarray] = None\n",
    "        self.ur_point: Optional[np.ndarray] = None\n",
    "        self.lr_point: Optional[np.ndarray] = None\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_line_equation(p1: np.ndarray, p2: np.ndarray) -> Tuple[float, float, float]:\n",
    "        x1, y1 = p1\n",
    "        x2, y2 = p2\n",
    "        A = y2 - y1\n",
    "        B = x1 - x2\n",
    "        C = (x2 - x1) * y1 - (y2 - y1) * x1\n",
    "        return (A, B, C)\n",
    "\n",
    "    def calculate_parallel_distance(\n",
    "        self,\n",
    "        line1: Tuple[float, float, float],\n",
    "        line2: Tuple[float, float, float]\n",
    "    ) -> Optional[float]:\n",
    "        A1, B1, C1 = line1\n",
    "        A2, B2, C2 = line2\n",
    "        if abs(A1 * B2 - A2 * B1) > 1e-6:\n",
    "            return None\n",
    "        return abs(C2 - C1) / math.hypot(A1, B1)\n",
    "\n",
    "    @staticmethod\n",
    "    def point_to_line_distance(point: np.ndarray, line: Tuple[float, float, float]) -> float:\n",
    "        x, y = point\n",
    "        A, B, C = line\n",
    "        return abs(A * x + B * y + C) / math.hypot(A, B)\n",
    "\n",
    "    def calculate_height(\n",
    "        self,\n",
    "        lower_line_eq: Tuple[float, float, float],\n",
    "        upper_line_eq: Tuple[float, float, float],\n",
    "        scale_factor: float\n",
    "    ) -> float:\n",
    "        h_pixels = self.calculate_parallel_distance(lower_line_eq, upper_line_eq)\n",
    "        d_ll = self.point_to_line_distance(self.ll_point, upper_line_eq) if self.ll_point is not None else 0\n",
    "        d_lr = self.point_to_line_distance(self.lr_point, upper_line_eq) if self.lr_point is not None else 0\n",
    "        avg_point_dist = (d_ll + d_lr) / 2\n",
    "        if h_pixels is None or abs(h_pixels - avg_point_dist) > 5:\n",
    "            return avg_point_dist * scale_factor\n",
    "        return ((h_pixels * 0.7) + (avg_point_dist * 0.3)) * scale_factor\n",
    "\n",
    "    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Optional[float]]:\n",
    "        results = self.model.predict(frame, verbose=False, conf=0.6)\n",
    "        if not results:\n",
    "            return frame, None\n",
    "        result = results[0]\n",
    "        annotated_frame = result.plot()\n",
    "        if result.keypoints is None or len(result.keypoints.xy[0]) < 4:\n",
    "            return annotated_frame, None\n",
    "        try:\n",
    "            kpts = result.keypoints.xy[0].cpu().numpy()\n",
    "            # Assume keypoint order: lower left, upper left, upper right, lower right.\n",
    "            self.ll_point, self.ul_point, self.ur_point, self.lr_point = kpts[:4]\n",
    "        except Exception as e:\n",
    "            print(f\"Keypoint extraction error: {e}\")\n",
    "            return annotated_frame, None\n",
    "\n",
    "        self.draw_debug_info(annotated_frame)\n",
    "\n",
    "        try:\n",
    "            lower_line_eq = self.calculate_line_equation(self.ll_point, self.lr_point)\n",
    "            upper_line_eq = self.calculate_line_equation(self.ul_point, self.ur_point)\n",
    "            lower_edge_px = np.linalg.norm(self.lr_point - self.ll_point)\n",
    "            upper_edge_px = np.linalg.norm(self.ur_point - self.ul_point)\n",
    "            if lower_edge_px <= 0 or upper_edge_px <= 0:\n",
    "                return annotated_frame, None\n",
    "            scale_factor = 1.0 / ((lower_edge_px + upper_edge_px) / 2.0)\n",
    "            height_cm = self.calculate_height(lower_line_eq, upper_line_eq, scale_factor)\n",
    "            if height_cm <= 0 or height_cm > 30:\n",
    "                return annotated_frame, None\n",
    "            volume = math.pi * (self.syringe_diameter / 2) ** 2 * height_cm\n",
    "            self.volume_history.append(volume)\n",
    "            smoothed_volume = float(np.median(self.volume_history))\n",
    "            return annotated_frame, smoothed_volume\n",
    "        except Exception as e:\n",
    "            print(f\"Processing error: {e}\")\n",
    "            return annotated_frame, None\n",
    "\n",
    "    def draw_debug_info(self, frame: np.ndarray) -> None:\n",
    "        debug_params = {\n",
    "            'fontFace': cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            'fontScale': 0.6,\n",
    "            'color': (0, 0, 255),\n",
    "            'thickness': 1\n",
    "        }\n",
    "        labels = ['LL', 'UL', 'UR', 'LR']\n",
    "        points = [self.ll_point, self.ul_point, self.ur_point, self.lr_point]\n",
    "        for label, pt in zip(labels, points):\n",
    "            if pt is not None:\n",
    "                cv2.putText(frame, label, (int(pt[0]) + 10, int(pt[1])), **debug_params)\n",
    "        if self.ll_point is not None and self.lr_point is not None:\n",
    "            lower_len = np.linalg.norm(self.lr_point - self.ll_point)\n",
    "            cv2.putText(frame, f\"Lower: {lower_len:.1f}px\", (10, 100), **debug_params)\n",
    "        if self.ul_point is not None and self.ur_point is not None:\n",
    "            upper_len = np.linalg.norm(self.ur_point - self.ul_point)\n",
    "            cv2.putText(frame, f\"Upper: {upper_len:.1f}px\", (10, 130), **debug_params)\n",
    "\n",
    "    def run_on_video(self, input_video_path: str, output_video_path: str) -> None:\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open video file: {input_video_path}\")\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if fps <= 0:\n",
    "            fps = 30\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        current_frame = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            processed_frame, volume = self.process_frame(frame)\n",
    "            if volume is not None:\n",
    "                cv2.putText(processed_frame, f\"Volume: {volume:.2f} mL\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                height_cm = volume / (math.pi * (self.syringe_diameter / 2) ** 2)\n",
    "                cv2.putText(processed_frame, f\"Height: {height_cm:.1f} cm\", (10, 70),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            out.write(processed_frame)\n",
    "            current_frame += 1\n",
    "            print(f\"Processing frame {current_frame}/{frame_count}\", end=\"\\r\")\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\nExport complete!\")\n",
    "\n",
    "# Set the paths for your video files.\n",
    "input_video_path: str = \"input_video.mp4\"   # Replace with the path to your input video file.\n",
    "output_video_path: str = \"output_video.mp4\" # Replace with the desired path for the output video.\n",
    "\n",
    "# Create an instance and run video processing.\n",
    "calculator = SyringeVolumeCalculator()\n",
    "calculator.run_on_video(input_video_path, output_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
