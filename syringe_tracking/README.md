# Object Detection and Tracking

This directory (`object_detection_tracking/`) contains the system for detecting objects in images/videos and tracking them across frames. It typically involves an object detection model (e.g., YOLO, SSD, Faster R-CNN) and a tracking algorithm (e.g., ByteTrack, DeepSORT, Kalman Filter).

## Purpose

This module identifies instances of specified objects in each frame and, if tracking is enabled, assigns a consistent ID to each detected object across multiple frames. This allows for monitoring object movement and behavior over time. The outputs can be used by a `../downstream_task/` component.

## Files (Example Structure)

-   `train_detector.py`: Script for training the object detection model.
-   `inference_video.ipynb`: Jupyter Notebook for running detection/tracking on video files.
-   `inference_webcam.ipynb`: Jupyter Notebook for real-time detection/tracking via webcam.
-   `tracker_config.yaml`: Configuration file for the tracking algorithm parameters.
-   `model_configs/`: Directory for detection model configuration files (e.g., `yolo_config.yaml`).
-   `trained_models/`: Directory to store trained model weights.
-   `runs/`: Default output directory for training experiments (logs, checkpoints, etc.).

## Usage

1.  **Prepare Dataset:**
    Ensure you have an annotated dataset suitable for training your chosen object detection model. Common formats include COCO, Pascal VOC, or YOLO. Annotations might be generated by the `../data_annotation/` component.

2.  **Train the Detection Model (Optional):**
    If you are not using a pre-trained model or need to fine-tune, train your detector using `train_detector.py`.
    ```bash
    python train_detector.py --data_config path/to/dataset.yaml --model_config model_configs/your_model_config.yaml --epochs 50
    ```
    Adjust parameters like dataset path, model configuration, epochs, image size, etc., as needed (often via a dataset YAML and model config file). Trained models are typically saved in `trained_models/` or within the `runs/` directory.

3.  **Run Inference:**
    -   **Video File:** Open and run `inference_video.ipynb`. Update paths to the video file and your trained model weights (e.g., `.pt`, `.pth`, `.weights`) within the notebook.
    -   **Webcam:** Open and run `inference_webcam.ipynb`. Set the correct webcam index and model paths.

## Configuration

-   **Detection Model:** Configuration for the detector (e.g., architecture, hyperparameters) is usually managed through a model-specific config file (e.g., in `model_configs/`) and/or command-line arguments to the training script.
-   **Tracker:** Modify `tracker_config.yaml` to adjust parameters for the chosen tracking algorithm (e.g., detection thresholds, association metrics, max age of tracks).
-   **Dataset:** For training, a dataset configuration file (often YAML) specifies paths to training/validation data and class names.
