{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO model from: runs/pose/train-pose11n-v25-P50/weights/best.pt\n",
      "Using device: mps\n",
      "DeepSORT tracker initialized successfully with specified parameters.\n",
      "Starting webcam input...\n",
      "WARNING ⚠️ Apple MPS known Pose bug. Recommend 'device=cpu' for Pose models. See https://github.com/ultralytics/ultralytics/issues/4031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 19:48:05.942 python[16327:5316961] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-27 19:48:05.942 python[16327:5316961] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime  # Needed for DeepSORT 'today' argument potentially\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Import DeepSORT\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# # Helper function to calculate IoU (No longer needed with 'others' method)\n",
    "# def calculate_iou(box1, box2):\n",
    "#     # ... (IoU calculation code removed) ...\n",
    "\n",
    "class SyringeVolumeEstimator:\n",
    "    # Added default values based on deepsort_tracker.py documentation\n",
    "    def __init__(self,\n",
    "                 max_iou_distance=0.7,\n",
    "                 max_age=30,\n",
    "                 n_init=3,\n",
    "                 nms_max_overlap=1.0,\n",
    "                 max_cosine_distance=0.2,\n",
    "                 nn_budget=None,\n",
    "                 embedder=\"mobilenet\", # Use default embedder\n",
    "                 half=True, # Use half precision for mobilenet if GPU\n",
    "                 bgr=True, # Input is BGR\n",
    "                 embedder_model_name=None,\n",
    "                 embedder_wts=None,\n",
    "                 polygon=False,\n",
    "                 ):\n",
    "        \"\"\"Initialize the YOLO model, DeepSORT tracker, device, and possible diameters, using parameters based on deep-sort-realtime v1.3.2 docs.\"\"\"\n",
    "        # Load and evaluate the YOLO *pose* model\n",
    "        self.model_path = \"runs/pose/train-pose11n-v25-P50/weights/best.pt\"\n",
    "        print(f\"Loading YOLO model from: {self.model_path}\")\n",
    "        if not os.path.exists(self.model_path):\n",
    "             raise FileNotFoundError(f\"YOLO model not found at {self.model_path}. Please ensure the path is correct.\")\n",
    "        self.model = YOLO(self.model_path)\n",
    "\n",
    "        # Set device based on availability\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available(): # More robust check for MPS\n",
    "            self.device = \"mps\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        # Determine if GPU should be used for the embedder\n",
    "        use_embedder_gpu = (self.device != 'cpu') # True if cuda or mps\n",
    "\n",
    "        # Initialize DeepSORT tracker based on v1.3.2 documentation\n",
    "        try:\n",
    "            self.tracker = DeepSort(\n",
    "                max_iou_distance=max_iou_distance,\n",
    "                max_age=max_age,\n",
    "                n_init=n_init,\n",
    "                nms_max_overlap=nms_max_overlap,\n",
    "                max_cosine_distance=max_cosine_distance,\n",
    "                nn_budget=nn_budget,\n",
    "                # override_track_class=None, # Optional: Use a custom Track class\n",
    "                embedder=embedder,          # Specify the embedder type\n",
    "                half=half,                  # Use half precision if GPU?\n",
    "                bgr=bgr,                    # Input color format\n",
    "                embedder_gpu=use_embedder_gpu, # Set GPU usage for embedder\n",
    "                embedder_model_name=embedder_model_name, # e.g., for torchreid\n",
    "                embedder_wts=embedder_wts,  # Path to specific weights\n",
    "                polygon=polygon,            # Using bounding boxes, not polygons\n",
    "                today=datetime.now().date() # Optional: for daily track ID reset\n",
    "            )\n",
    "            print(\"DeepSORT tracker initialized successfully with specified parameters.\")\n",
    "        except TypeError as e:\n",
    "             print(f\"Error initializing DeepSORT: {e}\")\n",
    "             print(\"Please double-check deep-sort-realtime installation and compatibility with provided arguments.\")\n",
    "             raise\n",
    "        except Exception as e:\n",
    "             print(f\"An unexpected error occurred during DeepSORT initialization: {e}\")\n",
    "             raise\n",
    "\n",
    "\n",
    "        # Define possible syringe diameters in cm\n",
    "        self.possible_diameters = [0.45, 1.0, 1.25, 2.0]\n",
    "\n",
    "    def draw_volume_table(self, frame: np.ndarray, volumes: list, table_x: int, table_y: int, track_id: str) -> None:\n",
    "        \"\"\"Draw a table on the frame showing diameters and volumes with track ID.\"\"\"\n",
    "        table_width = 250\n",
    "        table_height = 200  # For header, track ID, and 4 diameters\n",
    "\n",
    "        # Ensure coordinates are within frame bounds\n",
    "        frame_h, frame_w = frame.shape[:2]\n",
    "        table_x = max(0, min(table_x, frame_w - table_width))\n",
    "        table_y = max(0, min(table_y, frame_h - table_height))\n",
    "\n",
    "        # Draw light gray background\n",
    "        cv2.rectangle(frame, (table_x, table_y), (table_x + table_width, table_y + table_height), (220, 220, 220), -1)\n",
    "        # Draw track ID\n",
    "        cv2.putText(frame, f\"Syringe ID: {track_id}\", (table_x + 10, table_y + 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        # Draw headers\n",
    "        cv2.putText(frame, \"Diameter\", (table_x + 10, table_y + 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, \"mL\", (table_x + 150, table_y + 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "        # Draw rows for each diameter and volume\n",
    "        for i, (D, volume) in enumerate(volumes):\n",
    "            y = table_y + 80 + i * 30\n",
    "            cv2.putText(frame, f\"{D:.2f}\", (table_x + 10, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "            if volume is not None and not math.isnan(volume):\n",
    "                cv2.putText(frame, f\"{volume:.2f}\", (table_x + 150, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"N/A\", (table_x + 150, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    def process_frame(self, frame: np.ndarray, timestamp: float, writer: csv.writer) -> np.ndarray:\n",
    "        \"\"\"Process frame: Detect(YOLO) -> Track(DeepSORT using 'others') -> Calc Vol -> Log -> Draw.\"\"\"\n",
    "\n",
    "        # 1. Run YOLOv8 Pose Prediction\n",
    "        results = self.model.predict(source=frame, device=self.device, verbose=False, conf=0.6)\n",
    "        result = results[0] # Get results for the single frame\n",
    "        annotated_frame = frame.copy() # Work on a copy for annotations\n",
    "\n",
    "        # 2. Prepare Detections for DeepSORT & Supplementary Data ('others')\n",
    "        detections_for_deepsort = []\n",
    "        other_data_for_deepsort = [] # List to hold keypoints corresponding to detections\n",
    "\n",
    "        if result.boxes is not None and len(result.boxes) > 0:\n",
    "            for i, box in enumerate(result.boxes):\n",
    "                # Ensure keypoints exist for this detection index\n",
    "                if result.keypoints is None or len(result.keypoints.xy) <= i or result.keypoints.xy[i].shape[0] < 4:\n",
    "                    continue\n",
    "\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                conf = box.conf[0].cpu().numpy()\n",
    "                cls = int(box.cls[0].cpu().numpy())\n",
    "\n",
    "                # Convert xyxy to [left, top, width, height] for DeepSORT\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                if w <= 0 or h <= 0: continue # Skip invalid boxes\n",
    "                bbox_ltwh = [x1, y1, w, h]\n",
    "\n",
    "                # Add detection tuple: ( [left,top,w,h], confidence, detection_class )\n",
    "                detections_for_deepsort.append((bbox_ltwh, float(conf), cls))\n",
    "\n",
    "                # Store corresponding keypoints in the 'others' list\n",
    "                kpts = result.keypoints.xy[i].cpu().numpy()\n",
    "                other_data_for_deepsort.append(kpts)\n",
    "\n",
    "        # 3. Update DeepSORT Tracker, passing keypoints via 'others'\n",
    "        if detections_for_deepsort:\n",
    "             # Pass frame for built-in embedder, and keypoints via 'others'\n",
    "            tracks = self.tracker.update_tracks(detections_for_deepsort, frame=frame, others=other_data_for_deepsort)\n",
    "        else:\n",
    "            # Still call update_tracks with empty list if no detections\n",
    "            tracks = self.tracker.update_tracks([], frame=frame, others=[])\n",
    "\n",
    "        # 4. Process Active Tracks from DeepSORT\n",
    "        if not tracks:\n",
    "            # Log an empty row if no objects are tracked\n",
    "            row = [timestamp, np.nan, np.nan, np.nan] + [np.nan for _ in self.possible_diameters]\n",
    "            writer.writerow(row)\n",
    "            return annotated_frame\n",
    "\n",
    "        processed_track_ids = set() # Keep track of IDs processed in this frame\n",
    "\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "\n",
    "            track_id = track.track_id\n",
    "            if track_id in processed_track_ids:\n",
    "                continue\n",
    "            processed_track_ids.add(track_id)\n",
    "\n",
    "            # Get the *current* bounding box estimate from DeepSORT [x1, y1, x2, y2] using to_ltrb\n",
    "            # Use to_ltrb as per documentation (instead of potentially confusing to_tlbr)\n",
    "            bbox_ltrb_track = track.to_ltrb()\n",
    "            if bbox_ltrb_track is None: continue # Skip if track has no valid bbox yet\n",
    "            x1_track, y1_track, x2_track, y2_track = map(int, bbox_ltrb_track)\n",
    "\n",
    "            # --- Retrieve Keypoints using get_det_supplementary ---\n",
    "            kpts = track.get_det_supplementary()\n",
    "            # ----------------------------------------------------\n",
    "\n",
    "            if kpts is None or not isinstance(kpts, np.ndarray) or kpts.shape[0] < 4:\n",
    "                 # Draw box but log NaN for volumes if keypoints aren't found/valid\n",
    "                 cv2.rectangle(annotated_frame, (x1_track, y1_track), (x2_track, y2_track), (0, 255, 0), 2)\n",
    "                 cv2.putText(annotated_frame, f\"ID: {track_id} (No Kpts)\", (x1_track, y1_track - 10),\n",
    "                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                 center_x = (x1_track + x2_track) / 2.0\n",
    "                 center_y = (y1_track + y2_track) / 2.0\n",
    "                 volumes = [np.nan] * len(self.possible_diameters)\n",
    "                 row = [timestamp, track_id, center_x, center_y] + volumes\n",
    "                 writer.writerow(row)\n",
    "                 continue\n",
    "\n",
    "            # We have the track ID, the current bbox (ltrb), and the keypoints (kpts)\n",
    "            try:\n",
    "                center_x = (x1_track + x2_track) / 2.0\n",
    "                center_y = (y1_track + y2_track) / 2.0\n",
    "                ll_point, ul_point, ur_point, lr_point = kpts[:4]\n",
    "\n",
    "                # Calculate width and height in pixels from keypoints\n",
    "                width_pixels = (np.linalg.norm(lr_point - ll_point) + np.linalg.norm(ur_point - ul_point)) / 2.0\n",
    "                height_pixels = (np.linalg.norm(ul_point - ll_point) + np.linalg.norm(ur_point - lr_point)) / 2.0\n",
    "\n",
    "                volumes = []\n",
    "                if width_pixels <= 1e-6 or height_pixels <= 1e-6: # Check for near-zero dimensions\n",
    "                    volumes = [np.nan] * len(self.possible_diameters)\n",
    "                    # print(f\"Warning: Near-zero dimensions calculated for track {track_id}. Pixels: w={width_pixels:.2f}, h={height_pixels:.2f}\")\n",
    "                else:\n",
    "                    # Calculate volumes for all possible diameters\n",
    "                    for D in self.possible_diameters:\n",
    "                        scale_factor_D = D / width_pixels\n",
    "                        H_cm = height_pixels * scale_factor_D\n",
    "                        if 0 < H_cm <= 30:  # Validate height (max 30 cm)\n",
    "                            volume_D = math.pi * (D / 2.0) ** 2 * H_cm\n",
    "                        else:\n",
    "                            volume_D = np.nan\n",
    "                        volumes.append(volume_D)\n",
    "\n",
    "                # Log data to CSV\n",
    "                row = [timestamp, track_id, center_x, center_y] + volumes\n",
    "                writer.writerow(row)\n",
    "\n",
    "                # Draw DeepSORT's bounding box and ID\n",
    "                cv2.rectangle(annotated_frame, (x1_track, y1_track), (x2_track, y2_track), (0, 255, 0), 2) # Green for tracked box\n",
    "                cv2.putText(annotated_frame, f\"ID: {track_id}\", (x1_track, y1_track - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                # Draw volume table using DeepSORT's box coordinates\n",
    "                table_x = x2_track + 10  # Right of bounding box\n",
    "                table_y = y1_track       # Top of bounding box\n",
    "                self.draw_volume_table(annotated_frame, list(zip(self.possible_diameters, volumes)), table_x, table_y, track_id)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during volume calculation/drawing for track {track_id}: {e}\")\n",
    "                # Draw the box even if calculation fails\n",
    "                cv2.rectangle(annotated_frame, (x1_track, y1_track), (x2_track, y2_track), (0, 0, 255), 2) # Red for error\n",
    "                cv2.putText(annotated_frame, f\"ID: {track_id} (Error)\", (x1_track, y1_track - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                # Log NaN for volumes on error\n",
    "                center_x = (x1_track + x2_track) / 2.0\n",
    "                center_y = (y1_track + y2_track) / 2.0\n",
    "                volumes = [np.nan] * len(self.possible_diameters)\n",
    "                row = [timestamp, track_id, center_x, center_y] + volumes\n",
    "                writer.writerow(row)\n",
    "                continue\n",
    "\n",
    "        # If no detections were made by YOLO initially AND no tracks were updated/confirmed\n",
    "        if (result.boxes is None or len(result.boxes) == 0) and not processed_track_ids:\n",
    "             # This might be redundant if tracker handles empty updates correctly, but safe to keep\n",
    "            row = [timestamp, np.nan, np.nan, np.nan] + [np.nan for _ in self.possible_diameters]\n",
    "            writer.writerow(row)\n",
    "\n",
    "        return annotated_frame\n",
    "\n",
    "    def run(self, input_source='webcam', video_path=None, csv_path='syringe_data_deepsort_v1.3.2.csv'):\n",
    "        \"\"\"Run the main loop using DeepSORT v1.3.2 features.\"\"\"\n",
    "\n",
    "        # Set up video capture based on input source\n",
    "        if input_source == 'video':\n",
    "            if video_path is None:\n",
    "                raise ValueError(\"video_path must be provided for input_source='video'\")\n",
    "            if not os.path.exists(video_path):\n",
    "                 raise FileNotFoundError(f\"Video file not found at {video_path}\")\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v') # or 'XVID', 'MJPG'\n",
    "            base, ext = os.path.splitext(video_path)\n",
    "            output_path = f\"{base}_processed_deepsort_v1.3.2{ext}\"\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "            print(f\"Processing video: {video_path}, saving to: {output_path}\")\n",
    "        else:  # webcam\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            out = None\n",
    "            print(\"Starting webcam input...\")\n",
    "\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open {'video file ' + video_path if input_source == 'video' else 'webcam'}\")\n",
    "\n",
    "        # Check if CSV exists, create with header if not\n",
    "        write_header = not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0\n",
    "        with open(csv_path, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if write_header:\n",
    "                header = ['timestamp', 'track_id', 'center_x', 'center_y'] + [f'volume_D{D:.2f}' for D in self.possible_diameters]\n",
    "                writer.writerow(header)\n",
    "                print(f\"Created/Opened CSV for appending: {csv_path}\")\n",
    "\n",
    "            frame_count = 0\n",
    "            try:\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"End of input source or cannot read frame.\")\n",
    "                        break\n",
    "\n",
    "                    frame_count += 1\n",
    "                    if input_source == 'video':\n",
    "                        timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "                    else:\n",
    "                        timestamp = time.time()\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    annotated_frame = self.process_frame(frame, timestamp, writer)\n",
    "                    end_time = time.time()\n",
    "                    fps_current = 1.0 / (end_time - start_time) if (end_time - start_time) > 0 else 0\n",
    "\n",
    "                    cv2.putText(annotated_frame, f\"FPS: {fps_current:.2f}\", (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                    if out is not None:\n",
    "                        out.write(annotated_frame)\n",
    "\n",
    "                    cv2.imshow('Syringe Volume Measurement (DeepSORT v1.3.2)', annotated_frame)\n",
    "\n",
    "                    key = cv2.waitKey(1) & 0xFF\n",
    "                    if key == ord('q'):\n",
    "                        print(\"Quitting...\")\n",
    "                        break\n",
    "                    elif key == ord('p'): # Pause functionality\n",
    "                         print(\"Paused. Press any key to continue...\")\n",
    "                         cv2.waitKey(-1)\n",
    "\n",
    "            except Exception as e:\n",
    "                 print(f\"\\nAn error occurred during processing loop (frame {frame_count}): {e}\")\n",
    "                 import traceback\n",
    "                 traceback.print_exc()\n",
    "            finally:\n",
    "                print(f\"Processed {frame_count} frames.\")\n",
    "                cap.release()\n",
    "                if out is not None:\n",
    "                    out.release()\n",
    "                    print(f\"Output video saved to {output_path}\")\n",
    "                cv2.destroyAllWindows()\n",
    "                print(\"Resources released.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have the necessary libraries installed:\n",
    "    # pip install ultralytics opencv-python deep-sort-realtime==1.3.2 torch numpy torchvision\n",
    "    # For GPU embedder (default): ensure PyTorch with CUDA/MPS support is installed.\n",
    "    # You might also need specific ONNX runtime if using certain embedders: pip install onnxruntime (or onnxruntime-gpu)\n",
    "    try:\n",
    "        # Initialize with parameters from DeepSORT docs (adjust max_age etc. as needed)\n",
    "        estimator = SyringeVolumeEstimator(\n",
    "            max_age=50,         # Increased max_age slightly\n",
    "            n_init=3,\n",
    "            max_cosine_distance=0.3, # Adjusted cosine distance threshold\n",
    "            nn_budget=None,     # No budget limit on appearance features\n",
    "            embedder=\"mobilenet\", # Using the default built-in pytorch embedder\n",
    "            half=True,          # Use FP16 for embedder if on GPU\n",
    "            bgr=True            # OpenCV provides BGR frames\n",
    "            )\n",
    "\n",
    "        # --- Choose Input Source ---\n",
    "        USE_WEBCAM = True # Set to False to use video file\n",
    "\n",
    "        if USE_WEBCAM:\n",
    "             estimator.run(input_source='webcam')\n",
    "        else:\n",
    "             # --- IMPORTANT: SET YOUR VIDEO FILE PATH HERE ---\n",
    "             video_file = 'IMG_4952.mov' # <--- CHANGE THIS PATH\n",
    "             # ---------------------------------------------\n",
    "             if os.path.exists(video_file):\n",
    "                 estimator.run(input_source='video', video_path=video_file)\n",
    "             else:\n",
    "                 print(f\"Video file not found: {video_file}. Check the path.\")\n",
    "                 print(\"Please set the correct 'video_file' path in the script.\")\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "         print(f\"Initialization failed: {fnf_error}\")\n",
    "    except ImportError as imp_error:\n",
    "         print(f\"Import Error: {imp_error}. Have you installed all required libraries (ultralytics, opencv-python, deep-sort-realtime==1.3.2, torch, numpy, torchvision)?\")\n",
    "    except Exception as main_error:\n",
    "         print(f\"An unexpected error occurred: {main_error}\")\n",
    "         import traceback\n",
    "         traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo11-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
