# Syringe Volume Estimation via Keypoint Detection

This directory contains the system for estimating the liquid volume within a syringe by detecting keypoints (specifically the plunger tip and the barrel tip) using a YOLO-Pose model.

## Purpose

The core idea is to measure the distance between the detected plunger tip and barrel tip keypoints. Assuming a known syringe type (and thus diameter), this distance can be used to calculate the volume of the liquid column. This module often works in conjunction with the `syringe_tracking` module to first locate syringes before applying keypoint detection.

## Files

-   `train.py`: Script for training the YOLO-Pose model to detect syringe keypoints (plunger tip, barrel tip). Requires a pose estimation dataset.
-   `video_and_webcam_inference.ipynb`: Jupyter Notebook for running keypoint detection and volume estimation on both pre-recorded video files and live webcam streams. This notebook likely integrates detection (optional), tracking (using ByteTrack), keypoint estimation, and volume calculation.
-   `pose_visualizer.ipynb`: Jupyter Notebook potentially used for visualizing the pose estimation dataset or the results of the keypoint detection model.
-   `clean_syringe_data.ipynb`: Jupyter Notebook likely used for pre-processing or cleaning the syringe dataset before training or analysis.
-   `animate_tracking_history.py`: Python script to create animations visualizing the tracked paths or volume changes over time, possibly using data generated during inference.
-   `bytetrack_od.yaml`: Configuration file for the ByteTrack tracker, used if tracking is integrated within the inference notebook.
-   `runs/`: Default output directory for training results (models, logs, etc.) generated by `train.py`.

## Usage

1.  **Prepare Dataset:**
    Ensure you have a dataset suitable for training YOLO-Pose. Annotations should include keypoints for the plunger tip and barrel tip for each syringe instance.

2.  **Train the Pose Model (Optional):**
    If you need to train a custom pose estimation model, use the provided `train.py` script. This script utilizes the Ultralytics YOLO-Pose library.
    **Important:** Modify the parameters (like dataset path, model configuration, epochs, image size, etc.) directly *within* the `train.py` script itself.
    Once configured, execute the script from the terminal:
    ```bash
    python train.py
    ```
    Trained models will typically be saved in the `runs/pose/train*/weights/` directory.

3.  **Run Inference and Volume Estimation:**
    -   Open and run `video_and_webcam_inference.ipynb`.
    -   Configure the notebook to select the input source (video file path or webcam index).
    -   Set the path to your trained YOLO-Pose model weights (`.pt` file).
    -   Specify syringe parameters (e.g., diameter) if needed for accurate volume calculation.
    -   The notebook will perform detection/tracking (optional), keypoint estimation, calculate volume, and display results.

4.  **Visualize/Analyze (Optional):**
    -   Use `pose_visualizer.ipynb` to inspect pose data or results.
    -   Use `clean_syringe_data.ipynb` for data preparation tasks.
    -   Run `animate_tracking_history.py` to generate visualizations from saved tracking/volume data.

## Configuration

-   **Tracker:** Modify `bytetrack_od.yaml` if tracking is used and needs adjustment.
-   **Training:** YOLO-Pose training configuration is managed via a dataset YAML file and command-line arguments to `train.py`.
-   **Inference:** Parameters like model paths, input sources, and syringe dimensions are set within the `video_and_webcam_inference.ipynb` notebook.

## Dependencies

Ensure the necessary libraries specified in the root `environment.yml` are installed, particularly:
-   Ultralytics YOLO (including Pose estimation capabilities)
-   ByteTrack (`py-bytetrack`) (if used for tracking)
-   OpenCV (`opencv-python`)
-   NumPy
-   Pandas (for data handling/export)
-   Jupyter Notebook / Lab
